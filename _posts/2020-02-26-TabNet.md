# Exploring TabNet by Google

### Motivation for Post
At my company we're investigating deep learning as it applies to financial tabular data. This is a fairly under-researched area and so I've been conducting a lot of my own experiments. This has been great (I've learned a ton), but when you're at a start-up, "speedy results" is the name of the game. That's why I was thrilled to discover that Google recently published a paper called [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf). This post will essentially be my notepad as I explore the ins and outs of this approach. As such, this post will be very disorganized; I hope to write up a post that is more suited for public consumption in the future.

Important terms I felt ought to be defined for readers, or terms that I was familiar with but not well-versed in, are defined in a glossary at the end of the post

### 1 Introduction
Tree-based models still dominate the tabular world, largely because (1) there's no canonical, standard DNN architecture for tabular data that performs well and (2) tree-based models are typically more interpretable than DNNs. TabNet attempts to achieve both high performance and interpretability. Interpretability is achieved by using soft *feature selection* via attention mechanisms. This feature selection occurs at each "decision step" of the model by using *sequential attention*.

TabNet also provides a method for self-supervised learning on tabular data (read: pre-training), which makes it attractive for data sets with a lot of unlabeled data available. 

### 3 TabNet for Tabular Learning
The authors claim that the features selection not only aids interpretability but also improves performance because learning is focused on the most important/salient features. ("Through sparse selection of the most salient features, the learning capacity of a decision step is not wasted on irrelevant features, and thus the model becomes more parameter efficient.") Something else that's cool is that they claim the higher dimensionality of TabNet mimics ensembling done in tree-based methods.

Categorical features are mapped to learned embeddings. No global normalization is applied to the data set; only batch norm is applied. (Note - that does not mean you should not normalize your features before passing them into TabNet; you should!) Similar to methods in vision and language processing, TabNet process a data point over several steps and is regressive - the input to step i is the output from step (i-1). Each step is trying to limit the high dimensionality space to the most salient inputs. (Think of a CNN, how it convolves groups of inputs down to smaller dimensions, keeping only the most important parts necessary for a correct prediction. Or think of an LSTM, which has gates between steps that attempt to learn the most important information to let pass through. TabNet is really similar to an LSTM in that way.)

--- Under construction --- 

### 4 Tabular Self-Supervised Learning


### Hyperparameters
- $\gamma$ - relaxation parameter; determines at how many decision steps a feature is allowed to be used. If $\gamma = 1$, features are forced to only be used at one decision step. As $\gamma$ increases, features can be used at multiple decision steps.

### Glossary
- feature selection - Identifying some subset of the provided features that are most useful for the prediction task. There are two broad types: global feature selection and local or instance-wise feature selection. Global feature selection is based on the entire training set, local feature selection is obviously on a per-data-point basis
- salient - important; what matters to the network.
- sequential attention
